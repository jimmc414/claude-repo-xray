# Repo X-Ray Reference

Detailed API documentation for all X-Ray tools.

## configure.py (NEW)

### Purpose
Automatically detects project structure and generates configuration files. Eliminates manual setup for most repositories.

### Usage
```
python configure.py [directory] [--dry-run] [--backup] [--force]
```

### Arguments
| Argument | Type | Default | Description |
|----------|------|---------|-------------|
| `directory` | string | `.` | Project directory to analyze |
| `--dry-run` | flag | - | Preview without writing files |
| `--backup` | flag | - | Create .bak files before overwriting |
| `--force` | flag | - | Overwrite without prompting |

### Detection Features

| Feature | Method | Fallback |
|---------|--------|----------|
| **Project Root** | .git → pyproject.toml → setup.py | __init__.py density |
| **Root Package** | Import statement analysis | Largest package by file count |
| **Ignore Patterns** | .gitignore + defaults | Comprehensive defaults |
| **Priority Modules** | Folder name heuristics | Generic patterns |

### Output
```
============================================================
REPO X-RAY AUTO-CONFIGURATION
============================================================

[1/4] Detecting project root...
  Found: /path/to/project
  Method: git

[2/4] Detecting root package name...
  Found: mypackage

[3/4] Generating ignore patterns...
  Directories: 25
  Extensions: 21
  Files: 7

[4/4] Generating priority modules...
  critical: 3 patterns
  high: 2 patterns
  medium: 2 patterns
  low: 4 patterns
```

---

## mapper.py

### Purpose
Maps directory structure with token estimates. Identifies large files that may consume excessive context.

### Usage
```
python mapper.py [directory] [--json] [--summary]
```

### Arguments
| Argument | Type | Default | Description |
|----------|------|---------|-------------|
| `directory` | string | `.` | Directory to map |
| `--json` | flag | - | Output as JSON |
| `--summary` | flag | - | Summary only, no tree |

### Output Format (Text)
```
ROOT: src/
    core/
        workflow.py (8.2K tok)
        __init__.py (50 tok)
    models/
        user.py (4.1K tok) [MEDIUM]
        schema.py (12.5K tok) [!LARGE]

============================================================
SUMMARY
  Total files: 156
  Total tokens: 245K
  Context budget: ~122.5% of 200K window

LARGE FILES (>10K tokens) - Consider using skeleton.py instead:
   12.5K tok  models/schema.py
   ...
```

### Output Format (JSON)
```json
{
  "path": "/path/to/project",
  "total_tokens": 245000,
  "file_count": 156,
  "tree": ["ROOT: src/", "    core/", ...],
  "large_files": [
    {"path": "models/schema.py", "tokens": 12500, "formatted": "12.5K"}
  ]
}
```

---

## skeleton.py

### Purpose
Extracts Python file interfaces via AST parsing. Achieves ~95% token reduction by showing only signatures, docstring summaries, Pydantic fields, decorators, and line numbers.

### Usage
```
python skeleton.py <path> [--pattern GLOB] [--priority LEVEL] [--private] [--no-line-numbers] [--json]
```

### Arguments
| Argument | Type | Default | Description |
|----------|------|---------|-------------|
| `path` | string | required | File or directory to analyze |
| `--pattern` | string | - | Glob pattern filter (e.g., `**/base*.py`) |
| `--priority` | choice | - | Filter by priority: critical, high, medium, low |
| `--private` | flag | - | Include _private methods |
| `--no-line-numbers` | flag | - | Omit line number annotations |
| `--json` | flag | - | Output as JSON |

### Priority Levels
Defined in `configs/priority_modules.json` (auto-generated by configure.py):

| Level | Description | Common Folders |
|-------|-------------|----------------|
| critical | Core orchestration | main, app, core, workflow |
| high | Domain logic | models, schemas, api, services |
| medium | Infrastructure | utils, lib, common |
| low | Utilities | tests, docs, examples |

### Enhanced Features

| Feature | What It Shows | Example |
|---------|---------------|---------|
| Pydantic fields | Class attributes | `name: str = Field(...)  # L51` |
| Decorators | `@dataclass`, `@property` | `@dataclass` above class |
| Global constants | Module-level vars | `CONFIG = "value"  # L17` |
| Line numbers | Code location | `def method(): ...  # L42` |

### Output Format (Text)
```
# ============================================================
# FILE: src/core/workflow.py
# Tokens: 8200 -> 410 (95.0% reduction)
# ============================================================
"""Main workflow orchestration..."""

CONFIG = {"timeout": 30}  # L15

@dataclass
class WorkflowConfig:  # L20
    name: str  # L21
    timeout: int = 30  # L22

class Workflow:  # L25
    """Orchestrates the main process..."""

    def __init__(self, config: WorkflowConfig): ...  # L28
        """Initialize the workflow..."""

    async def run(self, goal: str) -> Results: ...  # L35
        """Execute the workflow..."""
```

### Output Format (JSON)
```json
{
  "files": [
    {
      "file": "src/core/workflow.py",
      "original_tokens": 8200,
      "skeleton_tokens": 410,
      "reduction": "95.0%",
      "skeleton": "class Workflow:..."
    }
  ],
  "summary": {
    "file_count": 1,
    "total_original_tokens": 8200,
    "total_skeleton_tokens": 410,
    "overall_reduction": "95.0%"
  }
}
```

---

## dependency_graph.py

### Purpose
Analyzes import relationships between Python modules. Identifies architectural layers and circular dependencies. **Now auto-detects root package from imports.**

### Usage
```
python dependency_graph.py [directory] [--root PACKAGE] [--focus STRING] [--source-dir PATH] [--no-auto-detect] [--mermaid] [--json]
```

### Arguments
| Argument | Type | Default | Description |
|----------|------|---------|-------------|
| `directory` | string | `.` | Directory to analyze |
| `--root` | string | auto | Root package name (auto-detected if not specified) |
| `--focus` | string | - | Focus on modules matching this string |
| `--orphans` | flag | - | Find files with zero importers (dead code candidates) |
| `--impact` | string | - | Calculate blast radius for specified file |
| `--source-dir` | string | auto | Override source root for module name generation |
| `--no-auto-detect` | flag | - | Disable auto-detection of root package |
| `--mermaid` | flag | - | Output as Mermaid.js diagram |
| `--json` | flag | - | Output as JSON |

### Source Root Detection
For projects with code in nested directories (e.g., `.claude/skills/repo-xray/scripts/`), the tool auto-detects the logical source root to generate correct module names. This enables proper import matching for sibling imports that use `sys.path` manipulation.

Use `--source-dir` to override if auto-detection fails.

### Orphan Detection
Finds files with no internal importers, excluding known entry point patterns:
- `main.py`, `__main__.py`, `cli.py`, `app.py`, `wsgi.py`, `asgi.py`
- `test_*.py`, `*_test.py`, `conftest.py`
- `setup.py`, `manage.py`
- Files containing `if __name__ == "__main__":`

Output includes confidence scores based on naming patterns.

### Impact Analysis
Calculates blast radius for a file showing:
- **Direct dependents**: Files that directly import this module
- **Transitive dependents**: Files affected through 2 levels of imports

Warns when changes have wide impact (>10 transitive dependents).

### Architectural Layers
The tool automatically categorizes modules using both import patterns AND naming conventions:

| Layer | Import Pattern | Keyword Hints |
|-------|---------------|---------------|
| **foundation** | High imported_by, low imports | util, utils, base, common, helper, config |
| **core** | Balanced | service, handler |
| **orchestration** | Low imported_by, high imports | manager, orchestrator, coordinator, workflow, pipeline |
| **leaf** | Minimal interaction | - |

### Output Format (Text)
```
======================================================================
DEPENDENCY GRAPH
======================================================================

ARCHITECTURAL LAYERS:
----------------------------------------

  ORCHESTRATION (3 modules):
    mypackage.core.workflow
      imported by: 2 | imports: 12
    mypackage.services.api
      imported by: 1 | imports: 8

  FOUNDATION (5 modules):
    mypackage.utils.base
      imported by: 15 | imports: 2
    mypackage.core.types
      imported by: 12 | imports: 0

CIRCULAR DEPENDENCIES (potential issues):
----------------------------------------
  mypackage.models.user <-> mypackage.models.schema

======================================================================
SUMMARY
  Total modules: 45
  Internal dependencies: 120
  Circular dependencies: 1
  External packages: 15
    Top: asyncio, dataclasses, json, logging, pathlib...
```

### Output Format (Mermaid)
```mermaid
graph TD
    subgraph ORCHESTRATION
        core_workflow[workflow]
        services_api[api]
    end
    subgraph CORE
        models_user[user]
        services_handler[handler]
    end
    subgraph FOUNDATION
        utils_base[base]
        utils_config[config]
    end
    core_workflow --> models_user
    core_workflow --> utils_base
    services_api --> services_handler
```

### Output Format (JSON)
```json
{
  "modules": {
    "mypackage.core.workflow": {
      "imports": ["mypackage.utils.base", "mypackage.models.user"],
      "imported_by": ["mypackage.cli.main"]
    }
  },
  "layers": {
    "foundation": ["mypackage.utils.base", "mypackage.core.types"],
    "core": ["mypackage.models.user"],
    "orchestration": ["mypackage.core.workflow"],
    "leaf": ["mypackage.cli.main"]
  },
  "circular_dependencies": [["mypackage.models.user", "mypackage.models.schema"]],
  "external_dependencies": {
    "mypackage.core.workflow": ["asyncio", "logging"]
  },
  "summary": {
    "total_modules": 45,
    "internal_edges": 120,
    "circular_count": 1
  }
}
```

---

## git_analysis.py

### Purpose
Analyzes git history to extract temporal signals: risk scoring, co-modification patterns, and file freshness. Identifies volatile files, hidden coupling, and maintenance activity.

### Usage
```
python git_analysis.py [directory] [--risk] [--coupling] [--freshness] [--json] [--months N]
```

### Arguments
| Argument | Type | Default | Description |
|----------|------|---------|-------------|
| `directory` | string | `.` | Directory to analyze (must be in a git repository) |
| `--risk` | flag | - | Calculate risk scores from churn, hotfixes, authors |
| `--coupling` | flag | - | Find co-modification pairs (hidden coupling) |
| `--freshness` | flag | - | Categorize files by last modification time |
| `--json` | flag | - | Output all analyses as combined JSON |
| `--months` | int | 6 | History period for risk analysis |

### Risk Scoring
Calculates a 0-1 risk score based on:
- **Churn (40%)**: Normalized commit count in period
- **Hotfixes (40%)**: Commits with fix/bug/urgent/revert keywords
- **Author Entropy (20%)**: Number of unique authors (higher = more coordination overhead)

### Output Format (Risk)
```
RISK   FILE                              FACTORS
0.87   src/api/auth.py                   churn:15 hotfix:3 authors:5
0.72   src/core/workflow.py              churn:8 hotfix:1 authors:3
```

### Coupling Analysis
Finds files that frequently change together, indicating hidden dependencies not visible in imports:
- Analyzes recent commits (default: 200)
- Counts co-occurrences for Python files
- Filters to pairs with >= 3 co-occurrences
- Skips bulk refactors (commits touching >20 files)

### Output Format (Coupling)
```
=== CO-MODIFICATION PAIRS ===
Files that change together (hidden coupling)
12   src/api/auth.py <-> src/api/session.py
8    src/models/user.py <-> src/db/user_repo.py
```

### Freshness Categories
| Category | Threshold | Meaning |
|----------|-----------|---------|
| Active | <30 days | Being maintained |
| Aging | 30-90 days | May need attention |
| Stale | 90-180 days | Possibly neglected |
| Dormant | >180 days | Stable or abandoned |

### Output Format (Freshness)
```
=== FRESHNESS ANALYSIS ===
ACTIVE (last 30 days): 45 files
AGING (30-90 days): 23 files
STALE (90-180 days): 8 files
DORMANT (>180 days): 12 files
  Oldest files:
    src/legacy/converter.py (412 days)
```

### Output Format (JSON)
```json
{
  "risk": [
    {"file": "src/api/auth.py", "risk_score": 0.87, "churn": 15, "hotfixes": 3, "authors": 5}
  ],
  "coupling": [
    {"file_a": "src/api/auth.py", "file_b": "src/api/session.py", "count": 12}
  ],
  "freshness": {
    "active": [{"file": "src/api/auth.py", "days": 5}],
    "aging": [],
    "stale": [],
    "dormant": [{"file": "src/legacy/old.py", "days": 412}]
  }
}
```

---

## generate_warm_start.py

### Purpose
Generates complete WARM_START.md documentation by combining all analysis tools. Automatically detects project structure and handles nested source directories.

### Usage
```
python generate_warm_start.py [directory] [-o OUTPUT] [--debug] [--json] [-v]
```

### Arguments
| Argument | Type | Default | Description |
|----------|------|---------|-------------|
| `directory` | string | `.` | Repository directory to analyze |
| `-o, --output` | string | `WARM_START.md` | Output file path |
| `--debug` | flag | - | Output raw JSON to `WARM_START_debug/` directory |
| `--json` | flag | - | Output raw data as JSON instead of markdown |
| `-v, --verbose` | flag | - | Show progress messages |

### Data Collection
Combines output from all tools:
- **mapper.py**: Token estimates, large file detection
- **dependency_graph.py**: Import graph, layers, orphans
- **git_analysis.py**: Risk scores, coupling, freshness
- **skeleton.py**: Class/method extraction for critical modules

### Debug Output
When `--debug` is specified, creates `WARM_START_debug/` with:
```
WARM_START_debug/
├── raw_data.json           # Complete collected data
├── section_01_context.json # Mermaid diagram data
├── section_02_overview.json
├── section_03_classes.json
├── section_06_hazards.json
├── section_09_layers.json
├── section_10_risk.json
├── section_11_coupling.json
└── section_12_deadcode.json
```

### Output Sections
| Section | Source | Content |
|---------|--------|---------|
| 1. System Context | dependency_graph --mermaid | Architecture diagram |
| 2. Architecture Overview | Pattern detection | Layer counts, patterns |
| 3. Critical Classes | Entry point detection | CLI scripts, __main__ blocks |
| 4. Data Flow | Template | Processing pipeline |
| 5. Entry Points | detect_entry_points() | CLI commands, Python API |
| 6. Context Hazards | mapper.py | Large files, skip directories |
| 7. Quick Verification | Template | Health check commands |
| 8. X-Ray Commands | Template | Tool usage reference |
| 9. Architecture Layers | dependency_graph | Foundation/Core/Orchestration |
| 10. Risk Assessment | git_analysis --risk | Volatile files |
| 11. Hidden Coupling | git_analysis --coupling | Co-modification pairs |
| 12. Potential Dead Code | --orphans, --freshness | Orphans, dormant files |

### Confidence Markers
Low-confidence sections include markers for optional enhancement:
```markdown
<!-- CONFIDENCE: 0.5 - Pattern-based generation, may benefit from enhancement -->
```

### Key Functions (API)
| Function | Purpose |
|----------|---------|
| `collect_all_data(directory, verbose)` | Gather all analysis data |
| `detect_project_name(directory)` | Find project name from pyproject.toml/setup.py |
| `detect_entry_points(directory, graph, layers)` | Find CLI scripts and __main__ blocks |
| `generate_architecture_overview(data)` | Create prose from patterns |
| `render_template(data)` | Fill template placeholders |
| `write_debug_output(data, output_dir)` | Write section JSON files |

---

## Library Modules

### lib/token_estimator.py

| Function | Signature | Description |
|----------|-----------|-------------|
| `estimate_tokens` | `(text: str) -> int` | Estimate tokens for string |
| `estimate_file_tokens` | `(filepath: str) -> int` | Estimate tokens for file |
| `categorize_size` | `(tokens: int) -> str` | Get size category tag |
| `format_token_count` | `(tokens: int) -> str` | Format for display |

### lib/ast_utils.py

| Function | Signature | Description |
|----------|-----------|-------------|
| `get_skeleton` | `(filepath: str, include_private: bool, include_line_numbers: bool) -> Tuple[str, int, int]` | Extract file skeleton |
| `parse_imports` | `(filepath: str) -> Tuple[List, List]` | Parse absolute/relative imports |
| `get_class_hierarchy` | `(filepath: str) -> Dict[str, List]` | Extract class inheritance |

---

## Configuration Files

### configs/ignore_patterns.json
Auto-generated by `configure.py`. Safe to customize.
```json
{
  "directories": ["__pycache__", ".git", "venv", "node_modules", ...],
  "extensions": [".pyc", ".log", ".pkl", ...],
  "files": ["*.log", "*.jsonl", ".DS_Store", ...],
  "_comment": "Auto-generated by configure.py. Safe to customize."
}
```

### configs/priority_modules.json
Auto-generated by `configure.py` based on folder names. Safe to customize.
```json
{
  "priority_patterns": {
    "critical": {"description": "...", "patterns": ["**/core/**/*.py", ...]},
    "high": {"description": "...", "patterns": ["**/models/**/*.py", ...]},
    "medium": {"description": "...", "patterns": []},
    "low": {"description": "...", "patterns": ["**/tests/**/*.py", ...]}
  },
  "entry_points": {
    "hints": ["Look for classes with 'Workflow' or 'App' in name", ...]
  },
  "architecture_keywords": {
    "class_patterns": ["Workflow", "Manager", "Base", ...],
    "method_patterns": ["run", "execute", "process", ...]
  },
  "_comment": "Auto-generated by configure.py based on folder structure."
}
```
